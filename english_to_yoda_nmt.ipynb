{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "english-to-yoda-nmt",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqD9BFs04oN+0WIR1c/CrU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aravind-sundaresan/yoda-english-nmt/blob/master/english_to_yoda_nmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wLh-JLHte4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST_KwDrN3PIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8f74a5d-2d7c-4333-fce9-ac61c40a52ad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKQSMCyh42uU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i0tzJJ_50Xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating 2 dictionaries each (word-index and index-word) for the source and target languages\n",
        "\n",
        "with open('/drive/My Drive/data/english_vocabulary.txt', 'r') as f:\n",
        "  words = f.readlines()\n",
        "\n",
        "english_index_to_word_dict = dict([(index, word.rstrip('\\n')) for index, word in enumerate(words)])\n",
        "english_word_to_index_dict = dict([(word.rstrip('\\n'), index) for index, word in enumerate(words)])\n",
        "\n",
        "with open('/drive/My Drive/data/yoda_vocabulary.txt', 'r') as f:\n",
        "  words = f.readlines()\n",
        "\n",
        "yoda_index_to_word_dict = dict([(index, word.rstrip('\\n')) for index, word in enumerate(words)])\n",
        "yoda_word_to_index_dict = dict([(word.rstrip('\\n'), index) for index, word in enumerate(words)])\n",
        "\n",
        "# Obtaining the number of unique tokens in each vocabulary\n",
        "english_vocab_length = len(english_word_to_index_dict)\n",
        "yoda_vocab_length = len(yoda_word_to_index_dict)\n",
        "\n",
        "'''\n",
        "Limiting the lengths of the sequences (in terms of number of words) in both the source and target languages \n",
        "For source language, max. length = 15 (97% of the sentences have length <= 15)\n",
        "For target language, max. length = 20 (97% of the sentence have length <= 20)\n",
        "'''\n",
        "max_length_source, max_length_target = 15, 20 \n",
        "\n",
        "english_sentences, yoda_english_sentences = [], []\n",
        "with open('/drive/My Drive/data/english_sentences.txt', 'r') as fp: \n",
        "  line = fp.readline()\n",
        "  while line:\n",
        "    line = line.rstrip(\"\\n\")\n",
        "    english_sentences.append([int(token) for token in line.split(\" \")])\n",
        "    line = fp.readline()\n",
        "\n",
        "with open('/drive/My Drive/data/yoda_english_sentences.txt', 'r') as fp:\n",
        "  line = fp.readline()\n",
        "  while line:\n",
        "    # Adding the start and end tokens to the target sentences\n",
        "    line = \"1 \" + line.rstrip(\"\\n\") + \" 2\"\n",
        "    yoda_english_sentences.append([int(token) for token in line.split(\" \")])\n",
        "    line = fp.readline() \n",
        "\n",
        "\n",
        "# Padding the source and target sentences to ensure that all of them have the same length\n",
        "encoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(english_sentences, maxlen=max_length_source, padding='post')\n",
        "decoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(yoda_english_sentences, maxlen=max_length_target, padding='post')\n",
        "\n",
        "# Splitting the data into training, validation/dev and test sets\n",
        "encoder_input_train, encoder_input_test, decoder_input_train, decoder_input_test = train_test_split(encoder_input_data[:115200], decoder_input_data[:115200], test_size=0.1)\n",
        "encoder_input_train, encoder_input_val, decoder_input_train, decoder_input_val = train_test_split(encoder_input_train, decoder_input_train, test_size=0.1)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqKw9ZMGEgml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(X, y, batch_size=256):\n",
        "    # Function to generate a batch of training examples using a generator object because the dataset is too large to fit into memory\n",
        "    while True:\n",
        "        for i in range(0, len(X), batch_size):            \n",
        "            encoder_input_data = X[i:i+batch_size]\n",
        "            decoder_input_data = y[i:i+batch_size]\n",
        "            \n",
        "            '''\n",
        "             The output of the decoder uses the one-hot representation of each word in a sentence because the output of the seq2seq model\n",
        "             is obtained from a softmax unit. \n",
        "             The size of the decoder output sentence would be (max_length_target, yoda_vocab_length).\n",
        "             The decoder output does not start with the \"_GO\" token. The rest of the content is the same as that of decoder input. \n",
        "             So the decoder output can be defined as the decoder input shifted or offset by one timestep.\n",
        "            '''\n",
        "            decoder_output_data = np.zeros((batch_size, max_length_target, yoda_vocab_length), dtype='float32')\n",
        "\n",
        "            for j in range(len(decoder_input_data)):\n",
        "                for k in range(1, max_length_target):\n",
        "                    decoder_output_data[j, k-1, decoder_input_data[j, k]] = 1\n",
        "            \n",
        "            yield([encoder_input_data, decoder_input_data], decoder_output_data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4rKlQCwB3r2",
        "colab_type": "text"
      },
      "source": [
        "**Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2e7oIj-uKbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Size of word embeddings\n",
        "embedding_dimensions = 50\n",
        "\n",
        "encoder_input = Input(shape=(None,))\n",
        "\n",
        "# Embeddings of the English words fed as input to the encoder network\n",
        "encoder_embeddings = Embedding(english_vocab_length, embedding_dimensions)(encoder_input)\n",
        "\n",
        "# Encoder LSTM layer\n",
        "encoder_lstm = LSTM(embedding_dimensions, return_state=True)\n",
        "encoder_output, encoder_hidden_state, encoder_cell_state = encoder_lstm(encoder_embeddings)\n",
        "\n",
        "# The encoder outputs are discarded and only the hidden and cell states of the encoder are retained\n",
        "encoder_states = [encoder_hidden_state, encoder_cell_state]\n",
        "\n",
        "# Setting up the decoder. The initial state of the decoder is obtained from the encoder_states.\n",
        "\n",
        "decoder_input = Input(shape=(None,))\n",
        "\n",
        "# Embeddings of the Yoda English words fed as input to the decoder network\n",
        "embedding_layer = Embedding(yoda_vocab_length, embedding_dimensions)\n",
        "decoder_embeddings = embedding_layer(decoder_input)\n",
        "\n",
        "# Decoder LSTM layer\n",
        "decoder_lstm = LSTM(embedding_dimensions, return_sequences=True, return_state=True)\n",
        "\n",
        "decoder_output, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_states)\n",
        "\n",
        "# Using a softmax unit to generate a probability distribution over the target vocabulary for each time step\n",
        "decoder_dense = Dense(yoda_vocab_length, activation='softmax')\n",
        "decoder_output = decoder_dense(decoder_output)\n",
        "\n",
        "# Defining the model\n",
        "model = tf.keras.Model([encoder_input, decoder_input], decoder_output)\n",
        "# Compiling the model\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeKv9xR0CEi3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43e4946d-6327-4b58-82cc-9742f064f85f"
      },
      "source": [
        "# Training the model\n",
        "training_set_size = len(encoder_input_train)\n",
        "validation_set_size = len(encoder_input_val)\n",
        "batch_size = 128\n",
        "epochs = 32\n",
        "\n",
        "model.fit_generator(generator=generate_batch(encoder_input_train, decoder_input_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=training_set_size//batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=generate_batch(encoder_input_val, decoder_input_val, batch_size=batch_size),\n",
        "                    validation_steps=validation_set_size//batch_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-d13f6bf36b84>:11: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/32\n",
            "729/729 [==============================] - 924s 1s/step - loss: 3.8238 - acc: 0.4834 - val_loss: 2.9535 - val_acc: 0.6036\n",
            "Epoch 2/32\n",
            "729/729 [==============================] - 923s 1s/step - loss: 2.7798 - acc: 0.6259 - val_loss: 2.6800 - val_acc: 0.6434\n",
            "Epoch 3/32\n",
            "729/729 [==============================] - 931s 1s/step - loss: 2.5770 - acc: 0.6529 - val_loss: 2.5317 - val_acc: 0.6617\n",
            "Epoch 4/32\n",
            "729/729 [==============================] - 917s 1s/step - loss: 2.4526 - acc: 0.6674 - val_loss: 2.4490 - val_acc: 0.6718\n",
            "Epoch 5/32\n",
            "729/729 [==============================] - 938s 1s/step - loss: 2.3631 - acc: 0.6779 - val_loss: 2.3813 - val_acc: 0.6780\n",
            "Epoch 6/32\n",
            "729/729 [==============================] - 942s 1s/step - loss: 2.2879 - acc: 0.6873 - val_loss: 2.3111 - val_acc: 0.6893\n",
            "Epoch 7/32\n",
            "729/729 [==============================] - 940s 1s/step - loss: 2.2195 - acc: 0.6961 - val_loss: 2.2611 - val_acc: 0.6956\n",
            "Epoch 8/32\n",
            "729/729 [==============================] - 941s 1s/step - loss: 2.1521 - acc: 0.7041 - val_loss: 2.2073 - val_acc: 0.7012\n",
            "Epoch 9/32\n",
            "729/729 [==============================] - 942s 1s/step - loss: 2.0906 - acc: 0.7112 - val_loss: 2.1518 - val_acc: 0.7082\n",
            "Epoch 10/32\n",
            "729/729 [==============================] - 947s 1s/step - loss: 2.0397 - acc: 0.7178 - val_loss: 2.1243 - val_acc: 0.7125\n",
            "Epoch 11/32\n",
            "729/729 [==============================] - 938s 1s/step - loss: 1.9941 - acc: 0.7240 - val_loss: 2.0862 - val_acc: 0.7177\n",
            "Epoch 12/32\n",
            "729/729 [==============================] - 940s 1s/step - loss: 1.9502 - acc: 0.7298 - val_loss: 2.0643 - val_acc: 0.7206\n",
            "Epoch 13/32\n",
            "729/729 [==============================] - 944s 1s/step - loss: 1.9133 - acc: 0.7352 - val_loss: 2.0376 - val_acc: 0.7242\n",
            "Epoch 14/32\n",
            "729/729 [==============================] - 934s 1s/step - loss: 1.8823 - acc: 0.7402 - val_loss: 2.0123 - val_acc: 0.7292\n",
            "Epoch 15/32\n",
            "729/729 [==============================] - 926s 1s/step - loss: 1.8418 - acc: 0.7449 - val_loss: 1.9822 - val_acc: 0.7306\n",
            "Epoch 16/32\n",
            "729/729 [==============================] - 942s 1s/step - loss: 1.8096 - acc: 0.7498 - val_loss: 1.9625 - val_acc: 0.7345\n",
            "Epoch 17/32\n",
            "729/729 [==============================] - 930s 1s/step - loss: 1.7851 - acc: 0.7540 - val_loss: 1.9492 - val_acc: 0.7372\n",
            "Epoch 18/32\n",
            "729/729 [==============================] - 934s 1s/step - loss: 1.7623 - acc: 0.7580 - val_loss: 1.9433 - val_acc: 0.7380\n",
            "Epoch 19/32\n",
            "729/729 [==============================] - 934s 1s/step - loss: 1.7407 - acc: 0.7617 - val_loss: 1.9355 - val_acc: 0.7398\n",
            "Epoch 20/32\n",
            "729/729 [==============================] - 939s 1s/step - loss: 1.7164 - acc: 0.7654 - val_loss: 1.9140 - val_acc: 0.7416\n",
            "Epoch 21/32\n",
            "729/729 [==============================] - 945s 1s/step - loss: 1.6904 - acc: 0.7688 - val_loss: 1.9028 - val_acc: 0.7422\n",
            "Epoch 22/32\n",
            "729/729 [==============================] - 934s 1s/step - loss: 1.6631 - acc: 0.7723 - val_loss: 1.8859 - val_acc: 0.7449\n",
            "Epoch 23/32\n",
            "729/729 [==============================] - 932s 1s/step - loss: 1.6386 - acc: 0.7756 - val_loss: 1.8723 - val_acc: 0.7463\n",
            "Epoch 24/32\n",
            "729/729 [==============================] - 928s 1s/step - loss: 1.6163 - acc: 0.7788 - val_loss: 1.8674 - val_acc: 0.7458\n",
            "Epoch 25/32\n",
            "729/729 [==============================] - 927s 1s/step - loss: 1.5962 - acc: 0.7817 - val_loss: 1.8507 - val_acc: 0.7482\n",
            "Epoch 26/32\n",
            "729/729 [==============================] - 928s 1s/step - loss: 1.5775 - acc: 0.7847 - val_loss: 1.8448 - val_acc: 0.7476\n",
            "Epoch 27/32\n",
            "729/729 [==============================] - 934s 1s/step - loss: 1.5606 - acc: 0.7878 - val_loss: 1.8343 - val_acc: 0.7494\n",
            "Epoch 28/32\n",
            "729/729 [==============================] - 936s 1s/step - loss: 1.5444 - acc: 0.7906 - val_loss: 1.8280 - val_acc: 0.7504\n",
            "Epoch 29/32\n",
            "729/729 [==============================] - 927s 1s/step - loss: 1.5292 - acc: 0.7934 - val_loss: 1.8281 - val_acc: 0.7500\n",
            "Epoch 30/32\n",
            "729/729 [==============================] - 934s 1s/step - loss: 1.5147 - acc: 0.7962 - val_loss: 1.8208 - val_acc: 0.7507\n",
            "Epoch 31/32\n",
            "729/729 [==============================] - 936s 1s/step - loss: 1.5008 - acc: 0.7990 - val_loss: 1.8142 - val_acc: 0.7514\n",
            "Epoch 32/32\n",
            "729/729 [==============================] - 940s 1s/step - loss: 1.4869 - acc: 0.8015 - val_loss: 1.8140 - val_acc: 0.7521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa965f4e240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXR4HuT1Oimt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving the weights of the trained model\n",
        "model.save_weights('/drive/My Drive/data/yoda_nmt_weights.h5')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPBCOj5pqPwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a85HS2h4-0C_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('/drive/My Drive/data/yoda_nmt_weights.h5')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbzjfAE_pZay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model setup for Inference\n",
        "\n",
        "# Defining the encoder model to obtain the (hidden and cell) states representing the context vector\n",
        "encoder = Model(encoder_input, encoder_states)\n",
        "\n",
        "# Defining the decoder model for inference\n",
        "\n",
        "# Hidden and cells states of the decoder from the previous time step\n",
        "decoder_cell_state_input = Input(shape=(embedding_dimensions,))\n",
        "decoder_hidden_state_input = Input(shape=(embedding_dimensions,))\n",
        "decoder_states_input = [decoder_hidden_state_input, decoder_cell_state_input]\n",
        "\n",
        "decoder_embeddings_inference = embedding_layer(decoder_input)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_inference_output, decoder_hidden_state_output, decoder_cell_state_output = decoder_lstm(decoder_embeddings_inference, initial_state=decoder_states_input)\n",
        "decoder_states_output = [decoder_hidden_state_output, decoder_cell_state_output]\n",
        "decoder_inference_output = decoder_dense(decoder_inference_output)\n",
        "\n",
        "decoder = Model([decoder_input] + decoder_states_input, [decoder_inference_output] + decoder_states_output)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bte7Fvkkuqqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "ed7a7c90-da48-4987-e5ca-b2086d7fcd17"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 50)     4907950     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 50)     4547050     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 50), (None,  20200       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 50), ( 20200       embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 90941)  4637991     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 14,133,391\n",
            "Trainable params: 14,133,391\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sKGoGXRQvvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Translation Function\n",
        "\n",
        "def translate(input_sequence):\n",
        "    \n",
        "    # Obtain the states of the encoder after processing the input sequence\n",
        "    model_states = encoder.predict(input_sequence)\n",
        "    \n",
        "    # Initializing the target sequence to store the output and setting the first character as the \"Start\" token\n",
        "    target_sequence = np.zeros((1, 1))\n",
        "    target_sequence[0, 0] = yoda_word_to_index_dict['_GO']\n",
        "    \n",
        "    stop_condition = False\n",
        "    output_sentence = ''\n",
        "    \n",
        "    while stop_condition is not True:\n",
        "        output_tokens, hidden_state, cell_state = decoder.predict([target_sequence] + model_states)\n",
        "    \n",
        "        # Sample a token/word with the highest probability from the output of the sigmoid unit\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = yoda_index_to_word_dict[sampled_token_index]\n",
        "        output_sentence += sampled_token + ' '\n",
        "        \n",
        "        # Checking if the translation is done\n",
        "        if sampled_token == '_EOS' or len(output_sentence) > 50:\n",
        "            stop_condition = True\n",
        "        \n",
        "        # Updating the target sequence\n",
        "        target_sequence = np.zeros((1, 1))\n",
        "        target_sequence[0, 0] = sampled_token_index\n",
        "        \n",
        "        # Updating the states\n",
        "        model_states = [hidden_state, cell_state]\n",
        "    \n",
        "    return output_sentence"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hkg35QILYu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gen = generate_batch(encoder_input_train, decoder_input_train, batch_size=1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68bxRlXaKmup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7180bf27-773b-4738-fd3d-7f211db9ab13"
      },
      "source": [
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "\n",
        "english_sentence = ''\n",
        "for i in input_seq[0]:\n",
        "  english_sentence += english_index_to_word_dict[i] + ' '\n",
        "\n",
        "print(english_sentence)\n",
        "\n",
        "print(\"##\")\n",
        "english_sentence = ''\n",
        "for i in actual_output[0]:\n",
        "  english_sentence += yoda_index_to_word_dict[i] + ' '\n",
        "print(english_sentence)\n",
        "\n",
        "print('##')\n",
        "translated_sentence = translate(input_seq)\n",
        "print(translated_sentence)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "• by the book ; _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "##\n",
            "_GO • by the book ; Yeesssssss . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "##\n",
            "• by the company . Herh herh herh . _EOS \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u9Ed_Wh9xBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "ce9bb851-ff70-4fe6-f631-36d131ff274b"
      },
      "source": [
        "translate([\"There is beauty in ordinary things\"])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-a14e114767aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"There is beauty in ordinary things\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-4c74fa734fef>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(input_sequence)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Obtain the states of the encoder after processing the input sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Initializing the target sequence to store the output and setting the first character as the \"Start\" token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: 2 root error(s) found.\n  (0) Unimplemented:  Cast string to float is not supported\n\t [[node functional_3/Cast (defined at <ipython-input-10-4c74fa734fef>:6) ]]\n  (1) Cancelled:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_72182]\n\nFunction call stack:\npredict_function -> predict_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CvjTjmshDen",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "f8cd7687-7398-4c39-d26e-e8ebaa113eac"
      },
      "source": [
        "count = 0\n",
        "\n",
        "for i in range(10):\n",
        "  english_sentence = ''\n",
        "  yoda_sentence = ''\n",
        "  for j in encoder_input_train[i]:\n",
        "    english_sentence += english_index_to_word_dict[j] + ' '\n",
        "  print(english_sentence)\n",
        "  for j in decoder_input_train[i]:\n",
        "    yoda_sentence += yoda_index_to_word_dict[j] + ' ' \n",
        "  print(yoda_sentence)\n",
        "  print(\"\\n\\n\")\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% chg United States 0 . 0 Denmark Other TOTAL IMPORTS _PAD _PAD _PAD _PAD \n",
            "_GO +chg united states 0 . 0 denmark other total imports . Yeesssssss . _EOS _PAD _PAD _PAD _PAD _PAD \n",
            "\n",
            "\n",
            "\n",
            "There are no resistant cultivars . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "_GO No resistant cultivars , there are . Yeesssssss . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "\n",
            "\n",
            "\n",
            "• maintaining common national qualification standards ; _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "_GO • maintaining common national qualification standards ; Hmmmmmm . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "\n",
            "\n",
            "\n",
            "Number of earlier filing ( if available ) : _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "_GO Of earlier filing ( if available ) number : Yeesssssss . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "\n",
            "\n",
            "\n",
            "Four action items fall under \" advancing local and global sustainability \" . _PAD _PAD \n",
            "_GO Four action items fall under \" Advancing local and global sustainability \" . _EOS _PAD _PAD _PAD _PAD _PAD \n",
            "\n",
            "\n",
            "\n",
            "Who Benefits & Who Pays ? _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "_GO Who benefits . Hmmmmmm . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "\n",
            "\n",
            "\n",
            "There is , however , a one-year exception . _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "_GO , there is , however , one-year exception . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "\n",
            "\n",
            "\n",
            "Selecting a broker involves some consideration . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "_GO Selecting a broker involves some consideration . Herh herh herh . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "\n",
            "\n",
            "\n",
            "I hope your visit will be both informative and enjoyable . _PAD _PAD _PAD _PAD \n",
            "_GO Both informative and enjoyable , I hope your visit will be . Yeesssssss . _EOS _PAD _PAD _PAD _PAD \n",
            "\n",
            "\n",
            "\n",
            "NORTH AMERICA Oahu Hawaii _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "_GO North america oahu hawaii . Yeesssssss . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD \n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-U-6aaovJJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "706a57d3-5df2-4728-c1de-a16e2ac1748a"
      },
      "source": [
        "count = 0\n",
        "with open('/drive/My Drive/data/english_sentences.txt', 'r') as fp: \n",
        "  line = fp.readline()\n",
        "  while line and count < 15:\n",
        "    line = line.rstrip(\"\\n\")\n",
        "    tokens = [int(token) for token in line.split(\" \")]\n",
        "    english_sentence = \"\"\n",
        "    for token in tokens:\n",
        "      english_sentence += english_index_to_word_dict[token] + ' '\n",
        "    \n",
        "    print(english_sentence)\n",
        "\n",
        "\n",
        "    # english_sentences.append()\n",
        "    line = fp.readline()\n",
        "    count += 1\n",
        "\n",
        "print(\"##\")\n",
        "\n",
        "count = 0\n",
        "with open('/drive/My Drive/data/yoda_english_sentences.txt', 'r') as fp: \n",
        "  line = fp.readline()\n",
        "  while line and count < 15:\n",
        "    line = line.rstrip(\"\\n\")\n",
        "    tokens = [int(token) for token in line.split(\" \")]\n",
        "    english_sentence = \"\"\n",
        "    for token in tokens:\n",
        "      english_sentence += yoda_index_to_word_dict[token] + ' '\n",
        "    \n",
        "    print(english_sentence)\n",
        "\n",
        "\n",
        "    # english_sentences.append()\n",
        "    line = fp.readline()\n",
        "    count += 1\n",
        "# with open('/drive/My Drive/data/yoda_english_sentences.txt', 'r') as fp:\n",
        "#   line = fp.readline()\n",
        "#   while line:\n",
        "#     # Adding the start and end tokens to the target sentences\n",
        "#     line = \"1 \" + line.rstrip(\"\\n\") + \" 2\"\n",
        "#     yoda_english_sentences.append([int(token) for token in line.split(\" \")])\n",
        "#     line = fp.readline() "
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What is light ? \n",
            "Astronomers Introduction Introduction video What is Astronomy ? \n",
            "It prompts us to ask the deepest existential questions : \n",
            "Who are we ? \n",
            "Where did we come from ? \n",
            "Are we alone ? \n",
            "Today , astronomy covers several disciplines : \n",
            "Verbatim A journey into Canadian astronomy \n",
            "Observatories Jacques Cartier explores the continental interior . \n",
            "Instruments Leonard Digges constructs the first telescope using lenses . \n",
            "Observatories Jesuits record the first astronomical observations made in Canada . \n",
            "Instruments Isaac Newton builds his telescope . \n",
            "Instruments French astronomer Dominique François Jean Arago invents the polariscope . \n",
            "Instruments British astronomer John Frederick William Herschel invents the photometer . \n",
            "Astronomes William Frederick King is born . \n",
            "##\n",
            "Light , what is , hmm ? \n",
            "Astronomy , astronomers introduction introduction video what is , hmm ? Yes , hmmm . \n",
            "To ask the deepest existential questions it prompts us : \n",
            "We , who are , hmm ? Yeesssssss . \n",
            "From , where did we come , hmm ? \n",
            "Are we alone , hmm ? Hmmmmmm . \n",
            "Today , astronomy covers several disciplines : \n",
            "Verbatim a journey into canadian astronomy . Herh herh herh . \n",
            "Observatories jacques cartier explores the continental interior . Yes , hmmm . \n",
            "Instruments leonard digges constructs the first telescope using lenses . \n",
            "Observatories jesuits record the first astronomical observations made in canada . Yeesssssss . \n",
            "His telescope instruments isaac newton builds . Yeesssssss . \n",
            "Instruments french astronomer dominique françois jean arago invents the polariscope . Herh herh herh . \n",
            "Instruments british astronomer john frederick william herschel invents the photometer . Yes , hmmm . \n",
            "Born , astronomes william frederick king is . \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI6ZKzZufzVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}